{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820f6c05-13e2-4ebf-9639-a10f7355f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Initializing Audio (Pygame Mixer)...\n",
      "Pygame Mixer ready. Loaded 'danger.mp3'.\n",
      "Initializing Text-to-Speech engine...\n",
      "TTS engine ready.\n",
      "Loading YOLOv8 model...\n",
      "Model loaded.\n",
      "Initializing Supervision components...\n",
      "Supervision components ready.\n",
      "Starting improved video processing loop...\n",
      "Defining tuned multi-layered proximity zones...\n",
      "All 3 custom zones defined.\n",
      "[FRAME 4] STATE CHANGE -> DANGER_PROBABLE | TTS: 'Caution! Too close!'\n",
      "Frame 30 | Peds: 1 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 60 | Peds: 1 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 90 | Peds: 1 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 120 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 150 | Peds: 0 | Vehicles: 7 | State: DANGER_PROBABLE\n",
      "Frame 180 | Peds: 0 | Vehicles: 7 | State: DANGER_PROBABLE\n",
      "Frame 210 | Peds: 0 | Vehicles: 7 | State: DANGER_PROBABLE\n",
      "Frame 240 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 270 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 300 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 330 | Peds: 0 | Vehicles: 7 | State: DANGER_PROBABLE\n",
      "Frame 360 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 390 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 420 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 450 | Peds: 0 | Vehicles: 8 | State: DANGER_PROBABLE\n",
      "Frame 480 | Peds: 0 | Vehicles: 8 | State: DANGER_PROBABLE\n",
      "Frame 510 | Peds: 0 | Vehicles: 8 | State: DANGER_PROBABLE\n",
      "Frame 540 | Peds: 0 | Vehicles: 8 | State: DANGER_PROBABLE\n",
      "!!! DANGER: Panning audio to X=1057.82861328125 !!!\n",
      "[FRAME 557] STATE CHANGE -> DANGER_IMMINENT | TTS: 'Collision Imminent!'\n",
      "Frame 570 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 600 | Peds: 1 | Vehicles: 5 | State: DANGER_IMMINENT\n",
      "Frame 630 | Peds: 0 | Vehicles: 8 | State: DANGER_IMMINENT\n",
      "Frame 660 | Peds: 1 | Vehicles: 6 | State: DANGER_IMMINENT\n",
      "Frame 690 | Peds: 1 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "[FRAME 705] STATE CHANGE -> DANGER_PROBABLE | TTS: 'Caution! Too close!'\n",
      "Frame 720 | Peds: 0 | Vehicles: 4 | State: DANGER_PROBABLE\n",
      "Frame 750 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 780 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 810 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 840 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Frame 870 | Peds: 0 | Vehicles: 4 | State: DANGER_PROBABLE\n",
      "Frame 900 | Peds: 0 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 930 | Peds: 2 | Vehicles: 5 | State: DANGER_PROBABLE\n",
      "Frame 960 | Peds: 2 | Vehicles: 4 | State: DANGER_PROBABLE\n",
      "Frame 990 | Peds: 2 | Vehicles: 3 | State: DANGER_PROBABLE\n",
      "Frame 1020 | Peds: 2 | Vehicles: 3 | State: DANGER_PROBABLE\n",
      "Frame 1050 | Peds: 2 | Vehicles: 2 | State: DANGER_PROBABLE\n",
      "Frame 1080 | Peds: 1 | Vehicles: 3 | State: DANGER_PROBABLE\n",
      "Frame 1110 | Peds: 1 | Vehicles: 3 | State: DANGER_PROBABLE\n",
      "Frame 1140 | Peds: 1 | Vehicles: 2 | State: DANGER_PROBABLE\n",
      "Frame 1170 | Peds: 0 | Vehicles: 3 | State: DANGER_PROBABLE\n",
      "Frame 1200 | Peds: 0 | Vehicles: 6 | State: DANGER_PROBABLE\n",
      "Video finished or failed to read a frame.\n",
      "Cleaning up resources...\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import pyttsx3\n",
    "import threading\n",
    "import pygame # <<< For directional audio\n",
    "import math # <<< For distance calculation\n",
    "\n",
    "# --- 1. Pygame Audio Engine (Directional) ---\n",
    "print(\"Initializing Audio (Pygame Mixer)...\")\n",
    "try:\n",
    "    pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=4096)\n",
    "    # ### MAKE SURE YOU HAVE THIS FILE ###\n",
    "    alert_sound = pygame.mixer.Sound('danger.mp3') \n",
    "    print(\"Pygame Mixer ready. Loaded 'danger.mp3'.\")\n",
    "except pygame.error as e:\n",
    "    print(f\"Error initializing pygame.mixer or loading file: {e}\")\n",
    "    print(\"### PLEASE MAKE SURE 'danger.mp3' IS IN THE FOLDER ###\")\n",
    "    alert_sound = None\n",
    "\n",
    "# --- 2. Text-to-Speech Engine ---\n",
    "print(\"Initializing Text-to-Speech engine...\")\n",
    "tts_engine = pyttsx3.init()\n",
    "tts_engine.setProperty('rate', 175)\n",
    "tts_engine.setProperty('volume', 1.0)\n",
    "print(\"TTS engine ready.\")\n",
    "\n",
    "# --- 3. Model & Supervision Components ---\n",
    "print(\"Loading YOLOv8 model...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "print(\"Initializing Supervision components...\")\n",
    "tracker = sv.ByteTrack()\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5, text_color=sv.Color.BLACK)\n",
    "print(\"Supervision components ready.\")\n",
    "\n",
    "personal_zone = None # (RENAMED) Will be defined on the first frame\n",
    "personal_zone_annotator = None # (RENAMED) Will be defined on the first frame\n",
    "\n",
    "# --- 4. Logic & State Variables ---\n",
    "object_history = {} # {track_id: [cx, cy, area, approach_count, last_seen_frame]}\n",
    "last_announced_state = \"SAFE\"\n",
    "last_alert_time = 0\n",
    "TTS_COOLDOWN = 3  # Cooldown in seconds between TTS alerts\n",
    "is_speaking = False\n",
    "\n",
    "# --- 5. Class Filtering ---\n",
    "# 0: person, 1: bicycle, 2: car, 3: motorcycle, 5: bus, 6: train, 7: truck, 9: traffic light\n",
    "TARGET_CLASS_IDS = [0, 1, 2, 3, 5, 6, 7, 9]\n",
    "VEHICLE_CLASS_IDS = [1, 2, 3, 5, 6, 7]\n",
    "CLASS_NAMES = model.model.names\n",
    "\n",
    "# --- 6. Tunables ---\n",
    "YOLO_CONF = 0.35              # Confidence threshold\n",
    "MIN_MOVE_DIST = 4.0             # Pixels an object must move to be 'moving'\n",
    "APPROACH_MULTIPLIER = 1.04      # 4% area growth to be 'approaching'\n",
    "APPROACH_SUSTAIN_FRAMES = 3     # Must grow for this many frames\n",
    "IOU_COLLISION_THRESHOLD = 0.05  # 10% overlap for IoU collision\n",
    "STALE_TRACK_FRAMES = 30         # Drop tracks not seen in this many frames\n",
    "STATE_STABLE_FRAMES = 3         # Require state to be stable for this long\n",
    "PATH_ALIGNMENT_THRESHOLD = 200  # Max X-distance for secondary \"approaching\" check\n",
    "CAUTION_X_DIST_MULTIPLIER = 1.75 # (NEW) Makes caution-zone 75% wider than danger-zone\n",
    "\n",
    "# --- 7. Helper Functions ---\n",
    "def say_alert(text_to_say):\n",
    "    \"\"\"Function to say text and manage speaking state.\"\"\"\n",
    "    global is_speaking\n",
    "    try:\n",
    "        tts_engine.say(text_to_say)\n",
    "        tts_engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in TTS: {e}\")\n",
    "    finally:\n",
    "        is_speaking = False\n",
    "\n",
    "def play_panned_alert(car_center_x, frame_width):\n",
    "    \"\"\"Plays the 'danger.mp3' sound, panned left or right.\"\"\"\n",
    "    if not alert_sound:\n",
    "        return\n",
    "    \n",
    "    pan = max(0.0, min(1.0, car_center_x / frame_width))\n",
    "    left_volume = 1.0 - pan\n",
    "    right_volume = pan\n",
    "    \n",
    "    try:\n",
    "        channel = pygame.mixer.find_channel(True) \n",
    "        channel.set_volume(left_volume, right_volume)\n",
    "        channel.play(alert_sound)\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing panned sound: {e}\")\n",
    "\n",
    "def is_collision(boxA, boxB, iou_threshold=0.02):\n",
    "    \"\"\"Check if two xyxy boxes intersect above an IoU threshold.\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    inter_w = max(0, xB - xA)\n",
    "    inter_h = max(0, yB - yA)\n",
    "    inter_area = inter_w * inter_h\n",
    "    if inter_area == 0:\n",
    "        return False\n",
    "\n",
    "    areaA = max(1, (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    areaB = max(1, (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "    iou = inter_area / float(areaA + areaB - inter_area)\n",
    "    return iou >= iou_threshold\n",
    "\n",
    "def box_center_and_area(xyxy):\n",
    "    cx = (xyxy[0] + xyxy[2]) / 2.0\n",
    "    cy = (xyxy[1] + xyxy[3]) / 2.0\n",
    "    area = max(1, (xyxy[2] - xyxy[0]) * (xyxy[3] - xyxy[1]))\n",
    "    return cx, cy, area\n",
    "\n",
    "# --- 8. Main Processing Loop ---\n",
    "video_path = 'sample3.mp4' # ### CHECK YOUR VIDEO PATH ###\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file at {video_path}\")\n",
    "else:\n",
    "    print(\"Starting improved video processing loop...\")\n",
    "    try:\n",
    "        stable_state = last_announced_state\n",
    "        stable_counter = 0\n",
    "        frame_idx = 0\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Video finished or failed to read a frame.\")\n",
    "                break\n",
    "\n",
    "            frame_idx += 1\n",
    "            # Get frame width/height for audio panning\n",
    "            frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "           # --- NEW: Define Multi-Layered Proximity Zones (Tuned) ---\n",
    "            if frame_idx == 1:\n",
    "                print(\"Defining tuned multi-layered proximity zones...\")\n",
    "                \n",
    "                # 1. DANGER ZONE (Red) - Your customized values\n",
    "                danger_points = np.array([\n",
    "                    (int(frame_width * 0.1), frame_height), # Bottom-left\n",
    "                    (int(frame_width * 0.9), frame_height), # Bottom-right\n",
    "                    (int(frame_width * 0.70), int(frame_height * 0.875)), # Top-right\n",
    "                    (int(frame_width * 0.30), int(frame_height * 0.875))  # Top-left\n",
    "                ], dtype=np.int32)\n",
    "                \n",
    "                danger_zone = sv.PolygonZone(polygon=danger_points)\n",
    "                danger_zone_annotator = sv.PolygonZoneAnnotator(\n",
    "                    zone=danger_zone, color=sv.Color.from_hex(\"#FF0000\"), # Red\n",
    "                    thickness=2, text_thickness=1, text_scale=0.5\n",
    "                )\n",
    "\n",
    "                # 2. CAUTION ZONE (Yellow) - Your customized values\n",
    "                caution_points = np.array([\n",
    "                    (int(frame_width * -0.2), frame_height), # Bottom-left\n",
    "                    (int(frame_width * 1.2), frame_height), # Bottom-right\n",
    "                    (int(frame_width * 0.80), int(frame_height * 0.75)), # Top-right\n",
    "                    (int(frame_width * 0.20), int(frame_height * 0.75))  # Top-left\n",
    "                ], dtype=np.int32)\n",
    "\n",
    "                caution_zone = sv.PolygonZone(polygon=caution_points)\n",
    "                caution_zone_annotator = sv.PolygonZoneAnnotator(\n",
    "                    zone=caution_zone, color=sv.Color.from_hex(\"#FFFF00\"), # Yellow\n",
    "                    thickness=2, text_thickness=1, text_scale=0.5\n",
    "                )\n",
    "\n",
    "                # 3. AWARENESS ZONE (Green) - Your customized values\n",
    "                awareness_points = np.array([\n",
    "                    (int(frame_width * -0.5), frame_height), # Bottom-left\n",
    "                    (int(frame_width * 1.5), frame_height), # Bottom-right\n",
    "                    (int(frame_width * 0.90), int(frame_height * 0.65)), # Top-right\n",
    "                    (int(frame_width * 0.10), int(frame_height * 0.65))  # Top-left\n",
    "                ], dtype=np.int32)\n",
    "                \n",
    "                awareness_zone = sv.PolygonZone(polygon=awareness_points)\n",
    "                awareness_zone_annotator = sv.PolygonZoneAnnotator(\n",
    "                    zone=awareness_zone, color=sv.Color.from_hex(\"#00FF00\"), # Green\n",
    "                    thickness=2, text_thickness=1, text_scale=0.5\n",
    "                )\n",
    "\n",
    "                print(\"All 3 custom zones defined.\")\n",
    "            # --- END ---\n",
    "\n",
    "            # 1. DETECT\n",
    "            results = model(frame, conf=YOLO_CONF, verbose=False)[0]\n",
    "\n",
    "            # 2. CONVERT & FILTER\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "            mask = np.isin(detections.class_id, TARGET_CLASS_IDS)\n",
    "            detections = detections[mask]\n",
    "\n",
    "            # 3. TRACK\n",
    "            tracked_detections = tracker.update_with_detections(detections)\n",
    "\n",
    "            # --- 4. ANALYZE ---\n",
    "            labels = []\n",
    "            pedestrians = []\n",
    "            vehicles = [] # List to hold all vehicle dicts\n",
    "            traffic_light_detected = False\n",
    "            seen_track_ids = set()\n",
    "\n",
    "            for xyxy, confidence, class_id, tracker_id in zip(\n",
    "                tracked_detections.xyxy,\n",
    "                tracked_detections.confidence,\n",
    "                tracked_detections.class_id,\n",
    "                tracked_detections.tracker_id\n",
    "            ):\n",
    "                xyxy = [float(x) for x in xyxy]\n",
    "                seen_track_ids.add(tracker_id)\n",
    "                class_name = CLASS_NAMES.get(class_id, \"Unknown\")\n",
    "                cx, cy, area = box_center_and_area(xyxy)\n",
    "\n",
    "                # --- State Calculation (FIXED) ---\n",
    "                is_moving = False\n",
    "                is_approaching = False\n",
    "                approach_count = 0\n",
    "\n",
    "                if tracker_id not in object_history:\n",
    "                    # First time seeing this object\n",
    "                    object_history[tracker_id] = [cx, cy, area, 0, frame_idx]\n",
    "                else:\n",
    "                    # Compare to previous state\n",
    "                    prev_x, prev_y, prev_area, prev_approach_count, _ = object_history[tracker_id]\n",
    "                    \n",
    "                    movement_distance = math.sqrt((cx - prev_x)**2 + (cy - prev_y)**2)\n",
    "                    is_moving = movement_distance > MIN_MOVE_DIST\n",
    "\n",
    "                    if area > (prev_area * APPROACH_MULTIPLIER):\n",
    "                        approach_count = min(10, prev_approach_count + 1) # Increment\n",
    "                    else:\n",
    "                        approach_count = max(0, prev_approach_count - 1) # Decrement\n",
    "                    \n",
    "                    is_approaching = approach_count >= APPROACH_SUSTAIN_FRAMES\n",
    "\n",
    "                # Update history with new values\n",
    "                object_history[tracker_id] = [cx, cy, area, approach_count, frame_idx]\n",
    "                # --- End State Calculation ---\n",
    "\n",
    "                # Build label text\n",
    "                label_text = f\"ID={tracker_id} {class_name} {confidence:.2f}\"\n",
    "                if is_moving:\n",
    "                    label_text += \" (Moving)\"\n",
    "                if is_approaching:\n",
    "                    label_text += \" (Approaching)\"\n",
    "\n",
    "                # Class-specific groupings\n",
    "                if class_id == 0:  # pedestrian\n",
    "                    pedestrians.append(xyxy)\n",
    "                elif class_id in VEHICLE_CLASS_IDS:\n",
    "                    vehicles.append({\n",
    "                        'xyxy': xyxy,\n",
    "                        'cx': cx,\n",
    "                        'area': area,\n",
    "                        'is_moving': is_moving,\n",
    "                        'is_approaching': is_approaching\n",
    "                    })\n",
    "                elif class_id == 9:\n",
    "                    traffic_light_detected = True\n",
    "\n",
    "                # Add label (once per loop)\n",
    "                labels.append(label_text)\n",
    "\n",
    "            # Prune stale tracks\n",
    "            stale_ids = [tid for tid, val in object_history.items() if (frame_idx - val[4]) > STALE_TRACK_FRAMES]\n",
    "            for tid in stale_ids:\n",
    "                del object_history[tid]\n",
    "\n",
    "            \n",
    "           # --- 5. DECIDE (Safety State) - NEW ESCALATION LOGIC ---\n",
    "            \n",
    "            # Get all potential obstacles\n",
    "            obstacle_mask = np.isin(tracked_detections.class_id, TARGET_CLASS_IDS) & (tracked_detections.class_id != 9)\n",
    "            obstacle_detections = tracked_detections[obstacle_mask]\n",
    "\n",
    "            # --- Check Zones in Priority Order ---\n",
    "            obstacles_in_danger_zone = danger_zone.trigger(detections=obstacle_detections)\n",
    "            obstacles_in_caution_zone = caution_zone.trigger(detections=obstacle_detections)\n",
    "            obstacles_in_awareness_zone = awareness_zone.trigger(detections=obstacle_detections)\n",
    "\n",
    "            # --- Set Defaults ---\n",
    "            current_state = \"SAFE\"\n",
    "            status_message = \"STATUS: SAFE\"\n",
    "            tts_message = None\n",
    "            danger_context = None\n",
    "\n",
    "            # --- Priority 1: DANGER ZONE (Red) ---\n",
    "            if np.any(obstacles_in_danger_zone):\n",
    "                # THIS IS THE KEY: Check if the *last* state was already a danger state\n",
    "                if stable_state == \"DANGER_PROBABLE\" or stable_state == \"DANGER_IMMINENT\":\n",
    "                    # It's a SUSTAINED danger. ESCALATE!\n",
    "                    current_state = \"DANGER_IMMINENT\"\n",
    "                    tts_message = \"Collision Imminent!\"\n",
    "                    status_message = \"DANGER: COLLISION IMMINENT!\"\n",
    "                else:\n",
    "                    # It's a NEW danger. Set to PROBABLE (Caution).\n",
    "                    current_state = \"DANGER_PROBABLE\"\n",
    "                    tts_message = \"Caution! Probable collision!\"\n",
    "                    status_message = \"CAUTION: PROBABLE COLLISION\"\n",
    "                \n",
    "                obs_coords = obstacle_detections[obstacles_in_danger_zone].xyxy[0]\n",
    "                obs_cx, _, _ = box_center_and_area(obs_coords)\n",
    "                danger_context = {'center_x': obs_cx}\n",
    "\n",
    "            # --- Priority 2: CAUTION ZONE (Yellow) ---\n",
    "            elif np.any(obstacles_in_caution_zone):\n",
    "                # Treat Yellow Zone as \"Probable\" danger\n",
    "                current_state = \"DANGER_PROBABLE\"\n",
    "                tts_message = \"Caution! Too close!\"\n",
    "                status_message = \"CAUTION: TOO CLOSE!\"\n",
    "                \n",
    "                obs_coords = obstacle_detections[obstacles_in_caution_zone].xyxy[0]\n",
    "                obs_cx, _, _ = box_center_and_area(obs_coords)\n",
    "                danger_context = {'center_x': obs_cx}\n",
    "\n",
    "            # --- Priority 3: AWARENESS ZONE (Green) ---\n",
    "            elif np.any(obstacles_in_awareness_zone):\n",
    "                current_state = \"CAUTION_NEARBY\"\n",
    "                tts_message = \"Caution. Obstacle nearby.\"\n",
    "                status_message = \"CAUTION: OBSTACLE NEARBY\"\n",
    "                danger_context = None\n",
    "\n",
    "            # --- Priority 4: Approaching Vehicle (Outside Zones) ---\n",
    "            elif vehicles:\n",
    "                caution_found = False\n",
    "                for v in vehicles:\n",
    "                    x_dist_from_center = abs(v['cx'] - (frame_width / 2.0))\n",
    "                    if (v['is_approaching'] and v['is_moving'] and \n",
    "                        x_dist_from_center < (PATH_ALIGNMENT_THRESHOLD * 1.5)):\n",
    "                        \n",
    "                        current_state = \"CAUTION_NEARBY\" # Use the new state\n",
    "                        tts_message = \"Caution. Approaching vehicle.\"\n",
    "                        status_message = \"CAUTION: APPROACHING VEHICLE\"\n",
    "                        danger_context = {'center_x': v['cx']}\n",
    "                        caution_found = True\n",
    "                        break\n",
    "                \n",
    "                if not caution_found and traffic_light_detected:\n",
    "                    current_state = \"CAUTION_NEARBY\" # Use the new state\n",
    "                    tts_message = \"Caution. Traffic light detected.\"\n",
    "                    status_message = \"CAUTION: TRAFFIC LIGHT\"\n",
    "            \n",
    "            # Priority 5: All Clear\n",
    "            else:\n",
    "                current_state = \"SAFE\"\n",
    "                status_message = \"STATUS: SAFE\"\n",
    "                tts_message = None\n",
    "                danger_context = None\n",
    "\n",
    "            # --- 6. SPEAK (TTS + Directional Audio) ---\n",
    "            current_time = time.time()\n",
    "            if current_state == stable_state:\n",
    "                stable_counter += 1\n",
    "            else:\n",
    "                stable_counter = 0\n",
    "                stable_state = current_state\n",
    "\n",
    "            # --- NEW STABILITY BYPASS (FIXED) ---\n",
    "            is_stable_enough = (stable_counter >= STATE_STABLE_FRAMES)\n",
    "\n",
    "            # BYPASS: Instantly alert ONLY for \"Imminent\" danger\n",
    "            if current_state == \"DANGER_IMMINENT\": # <<< FIX 1: Only bypass for imminent\n",
    "                is_stable_enough = True\n",
    "            # --- END BYPASS ---\n",
    "\n",
    "            # Check if we should speak\n",
    "            if ( is_stable_enough\n",
    "                 and current_state != last_announced_state\n",
    "                 and (current_time - last_alert_time) > TTS_COOLDOWN\n",
    "                 and not is_speaking\n",
    "                 and tts_message is not None):\n",
    "                \n",
    "                # --- Trigger Audio ---\n",
    "                # Play panned sound ONLY for \"Imminent\" danger\n",
    "                if current_state == \"DANGER_IMMINENT\" and danger_context: # <<< FIX 2: Only beep for imminent\n",
    "                    print(f\"!!! DANGER: Panning audio to X={danger_context['center_x']} !!!\")\n",
    "                    play_panned_alert(danger_context['center_x'], frame_width)\n",
    "\n",
    "                # --- Start non-blocking TTS ---\n",
    "                is_speaking = True\n",
    "                last_alert_time = current_time\n",
    "                last_announced_state = current_state \n",
    "                print(f\"[FRAME {frame_idx}] STATE CHANGE -> {current_state} | TTS: '{tts_message}'\")\n",
    "                threading.Thread(target=say_alert, args=(tts_message,), daemon=True).start()\n",
    "                # --- End Audio ---\n",
    "\n",
    "            # --- 7. ANNOTATE ---\n",
    "            annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=tracked_detections)\n",
    "            annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=tracked_detections, labels=labels)\n",
    "\n",
    "           # --- NEW: Draw All Proximity Zones ---\n",
    "            if awareness_zone_annotator:\n",
    "                annotated_frame = awareness_zone_annotator.annotate(scene=annotated_frame, label=\"NEARBY\")\n",
    "            if caution_zone_annotator:\n",
    "                annotated_frame = caution_zone_annotator.annotate(scene=annotated_frame, label=\"TOO CLOSE\")\n",
    "            if danger_zone_annotator:\n",
    "                annotated_frame = danger_zone_annotator.annotate(scene=annotated_frame, label=\"DANGER ZONE\")\n",
    "            # --- END NEW ---\n",
    "\n",
    "            # --- NEW: Highlight boxes based on ZONE ---\n",
    "            if current_state == \"DANGER\" or current_state == \"CAUTION\":\n",
    "                # Get all obstacle boxes that are in the zones\n",
    "                danger_boxes = obstacle_detections[obstacles_in_danger_zone].xyxy\n",
    "                caution_boxes = obstacle_detections[obstacles_in_caution_zone].xyxy\n",
    "                \n",
    "                # Draw red boxes for danger\n",
    "                for x1, y1, x2, y2 in danger_boxes:\n",
    "                    cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 3) # Red, thick\n",
    "                \n",
    "                # Draw yellow boxes for caution\n",
    "                for x1, y1, x2, y2 in caution_boxes:\n",
    "                    cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,255), 2) # Yellow\n",
    "            # --- END NEW ---\n",
    "\n",
    "            # Status text\n",
    "            status_color = (0, 0, 255) # Default Red for DANGER\n",
    "            if current_state == \"SAFE\":\n",
    "                status_color = (0, 255, 0) # Green\n",
    "            elif current_state == \"CAUTION_NEARBY\" or current_state == \"DANGER_PROBABLE\":\n",
    "                status_color = (0, 255, 255) # Yellow\n",
    "            \n",
    "            # Use the status_message from the DECIDE block\n",
    "            cv2.putText(annotated_frame, status_message, (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.2, status_color, 3, cv2.LINE_AA)\n",
    "\n",
    "            # --- 8. DISPLAY & DEBUG OUTPUT ---\n",
    "            cv2.imshow(\"YOLOv8 + Supervision Tracking (Improved)\", annotated_frame)\n",
    "            \n",
    "            # Debug print (FIXED)\n",
    "            if frame_idx % 30 == 0:\n",
    "                print(f\"Frame {frame_idx} | Peds: {len(pedestrians)} | Vehicles: {len(vehicles)} | State: {current_state}\")\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"'q' key pressed. Exiting...\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Process interrupted by user.\")\n",
    "    finally:\n",
    "        print(\"Cleaning up resources...\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        pygame.mixer.quit() # Quit pygame\n",
    "        print(\"Script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
